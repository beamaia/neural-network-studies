{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will follow a [PyTorch tutorial](https://pytorch-tutorial.readthedocs.io/en/latest/tutorial/chapter03_intermediate/3_2_2_cnn_resnet_cifar10/) implementing [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf) with CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters (attempt changing them later)\n",
    "num_epochs = 80\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image preprocessing modules (see more about this later)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../cifar-10-batches-py/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../cifar-10-batches-py/cifar-10-python.tar.gz to ../cifar-10-batches-py/\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='../cifar-10-batches-py/',\n",
    "                                             train=True, \n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../cifar-10-batches-py/',\n",
    "                                            train=False, \n",
    "                                            transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ../cifar-10-batches-py/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Pad(padding=4, fill=0, padding_mode=constant)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               RandomCrop(size=(32, 32), padding=None)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.cifar.CIFAR10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ../cifar-10-batches-py/\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff924a75d00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_dataset.data[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True) #Original tutorial has shuffle=True\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7ff923cd2a90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import conv3x3, ResidualBlock, ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_args = {\n",
    "    \"block\" : ResidualBlock,\n",
    "    \"layers\": [2, 2, 2]\n",
    "}\n",
    "\n",
    "model = ResNet(**net_args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lr(optimizer, lr):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(train_loader)\n",
    "curr_lr = learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  of  80\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 1, 3, 3], expected input[100, 3, 32, 32] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d5b24f443dc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ic-redes-neurais/neural-network-studies/intro_resnet/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 349\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    350\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 1, 3, 3], expected input[100, 3, 32, 32] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch \", epoch, \" of \", num_epochs)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    # Decay learning rate\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<span style=\"color: blue\"><b>Study session observations: </b></span>\n",
    "\n",
    "#### 16/07/2020:\n",
    "Attempting to use the same resnet model to train CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
