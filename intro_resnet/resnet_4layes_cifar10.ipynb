{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt at adding a layer to the previous ResNet model created following [kaggle notebook ResNet for MNIST with PyTorch](https://www.kaggle.com/readilen/resnet-for-mnist-with-pytorch?scriptVersionId=6942243) and the [PyTorch Tutorial on implementation of a ResNet model](https://pytorch-tutorial.readthedocs.io/en/latest/tutorial/chapter03_intermediate/3_2_2_cnn_resnet_cifar10/) to see what happens, if the accuracy increases. Code is due to [Liu Kuangs's extensive code](https://github.com/kuangliu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='../cifar-10-batches-py/',\n",
    "                                             train=True, \n",
    "                                             transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../cifar-10-batches-py/',\n",
    "                                            train=False, \n",
    "                                            transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True) #Original tutorial has shuffle=True\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating classes and functions related to ResNet with 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    print(\"function conv3x3\")\n",
    "    print(\"In channels \", in_channels)\n",
    "    print(\"Out channels \", out_channels)\n",
    "    return nn.Conv2d(in_channels,\n",
    "                     out_channels,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding=1,\n",
    "                     bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(\"ResidualBlock forward\")\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "            \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        print(\"conv\")\n",
    "        self.conv = conv3x3(3, 16)  # 1 when using mnist, 3 when using cifar10\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        print(\"\\nlayer1\")\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        print(\"\\nlayer2\")\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
    "        print(\"\\nlayer3\")\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
    "        print(\"\\nlayer4\")\n",
    "        self.layer4 = self.make_layer(block, 128, layers[3], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        \n",
    "    \n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        \n",
    "        downsample = None\n",
    "        \n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        \n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(\"ResNet forward\")\n",
    "        print(x.shape)\n",
    "        print(type(x))\n",
    "        print(self.conv.weight)\n",
    "        print(self.conv.weight.shape)\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv\n",
      "function conv3x3\n",
      "In channels  3\n",
      "Out channels  16\n",
      "\n",
      "layer1\n",
      "function conv3x3\n",
      "In channels  16\n",
      "Out channels  16\n",
      "function conv3x3\n",
      "In channels  16\n",
      "Out channels  16\n",
      "function conv3x3\n",
      "In channels  16\n",
      "Out channels  16\n",
      "function conv3x3\n",
      "In channels  16\n",
      "Out channels  16\n",
      "\n",
      "layer2\n",
      "function conv3x3\n",
      "In channels  16\n",
      "Out channels  32\n",
      "function conv3x3\n",
      "In channels  16\n",
      "Out channels  32\n",
      "function conv3x3\n",
      "In channels  32\n",
      "Out channels  32\n",
      "function conv3x3\n",
      "In channels  32\n",
      "Out channels  32\n",
      "function conv3x3\n",
      "In channels  32\n",
      "Out channels  32\n",
      "\n",
      "layer3\n",
      "function conv3x3\n",
      "In channels  32\n",
      "Out channels  64\n",
      "function conv3x3\n",
      "In channels  32\n",
      "Out channels  64\n",
      "function conv3x3\n",
      "In channels  64\n",
      "Out channels  64\n",
      "function conv3x3\n",
      "In channels  64\n",
      "Out channels  64\n",
      "function conv3x3\n",
      "In channels  64\n",
      "Out channels  64\n",
      "\n",
      "layer4\n",
      "function conv3x3\n",
      "In channels  64\n",
      "Out channels  128\n",
      "function conv3x3\n",
      "In channels  64\n",
      "Out channels  128\n",
      "function conv3x3\n",
      "In channels  128\n",
      "Out channels  128\n",
      "function conv3x3\n",
      "In channels  128\n",
      "Out channels  128\n",
      "function conv3x3\n",
      "In channels  128\n",
      "Out channels  128\n"
     ]
    }
   ],
   "source": [
    "net_args = {\n",
    "    \"block\" : ResidualBlock,\n",
    "    \"layers\": [2, 2, 2, 2]\n",
    "}\n",
    "\n",
    "model = ResNet(**net_args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 80\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lr(optimizer, lr):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(train_loader)\n",
    "curr_lr = learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet forward\n",
      "torch.Size([100, 1, 32, 32])\n",
      "<class 'torch.Tensor'>\n",
      "Parameter containing:\n",
      "tensor([[[[-7.4735e-02,  1.3674e-01,  6.0271e-02],\n",
      "          [ 1.7892e-01, -1.8771e-01, -1.4566e-01],\n",
      "          [ 7.8874e-02,  3.9991e-02,  1.2911e-01]],\n",
      "\n",
      "         [[-3.7161e-02, -8.2767e-02,  7.3420e-02],\n",
      "          [ 1.3777e-01, -7.3602e-02, -1.1098e-01],\n",
      "          [-3.8359e-02,  4.4810e-02, -1.6561e-01]],\n",
      "\n",
      "         [[ 1.4400e-01, -1.2958e-01,  2.7100e-02],\n",
      "          [-8.7010e-03,  6.8463e-02,  1.3647e-01],\n",
      "          [-1.0501e-01, -1.2591e-01, -7.0783e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6773e-01,  1.2532e-01, -1.0948e-01],\n",
      "          [-1.0701e-01, -1.4782e-01, -1.4778e-01],\n",
      "          [-1.6182e-01,  4.3212e-02, -1.5102e-01]],\n",
      "\n",
      "         [[-1.6138e-01,  1.0512e-01, -6.4897e-02],\n",
      "          [ 6.8898e-02, -9.2888e-02,  1.8196e-01],\n",
      "          [ 5.6517e-02, -1.6841e-02, -1.2339e-01]],\n",
      "\n",
      "         [[-1.8738e-01,  1.8412e-01, -1.3791e-01],\n",
      "          [-6.1126e-02,  1.8902e-01, -5.1872e-02],\n",
      "          [ 8.8434e-02, -1.4609e-01, -1.8380e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0901e-01,  1.3184e-01, -1.8351e-01],\n",
      "          [-1.3624e-01, -7.4528e-02, -1.5786e-01],\n",
      "          [-6.1576e-02,  3.6146e-02, -1.2806e-01]],\n",
      "\n",
      "         [[ 1.5609e-01,  1.7160e-01,  5.7107e-03],\n",
      "          [-1.2746e-02,  9.8038e-02,  3.6246e-02],\n",
      "          [ 4.4778e-02, -1.4537e-02,  8.8379e-02]],\n",
      "\n",
      "         [[ 1.4437e-01,  1.0044e-01,  1.7703e-01],\n",
      "          [ 1.6385e-02, -1.4192e-01, -1.0150e-01],\n",
      "          [ 1.0528e-01, -1.7618e-01, -1.3549e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.3329e-02, -7.5015e-02, -1.1720e-01],\n",
      "          [ 1.0225e-01, -1.5017e-01,  1.1017e-01],\n",
      "          [ 1.2314e-01,  1.2569e-01,  5.7094e-02]],\n",
      "\n",
      "         [[-7.7755e-02, -1.9108e-01,  1.7353e-01],\n",
      "          [ 1.9579e-04, -2.9075e-02, -1.4882e-01],\n",
      "          [-1.0698e-01, -6.6963e-02,  3.0988e-02]],\n",
      "\n",
      "         [[ 1.4316e-01,  1.1373e-01,  6.1273e-02],\n",
      "          [ 1.1600e-01, -5.6219e-02, -5.9145e-02],\n",
      "          [ 6.9062e-02,  1.8234e-01,  4.7509e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7330e-02,  1.2068e-01,  7.1949e-02],\n",
      "          [-1.0710e-01, -1.8750e-01,  6.6635e-02],\n",
      "          [-2.2249e-02, -1.8001e-01, -4.5516e-02]],\n",
      "\n",
      "         [[ 9.6277e-02, -9.3643e-02,  1.3331e-01],\n",
      "          [-1.1964e-01, -3.8507e-02,  1.4780e-01],\n",
      "          [-5.1087e-02,  1.7125e-01, -8.4921e-02]],\n",
      "\n",
      "         [[ 3.8870e-02, -6.2448e-02, -4.4571e-02],\n",
      "          [ 1.5419e-01, -1.9242e-01,  9.5687e-02],\n",
      "          [-8.2351e-02,  1.5442e-01, -4.0118e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6178e-04, -3.3997e-02,  5.5263e-03],\n",
      "          [-1.1788e-01,  1.7092e-01, -1.6732e-01],\n",
      "          [ 9.6962e-02,  4.2568e-03, -6.5978e-02]],\n",
      "\n",
      "         [[-8.0316e-02, -9.6506e-02, -1.1556e-01],\n",
      "          [-1.0792e-01,  7.6295e-02, -1.3060e-01],\n",
      "          [-2.6294e-02,  1.9186e-01,  2.3884e-02]],\n",
      "\n",
      "         [[-8.0279e-02,  9.3345e-02, -1.2957e-01],\n",
      "          [ 5.5096e-03, -1.5102e-01,  3.9489e-02],\n",
      "          [-1.6220e-01, -9.9791e-02,  1.8459e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5581e-01,  1.5454e-01,  4.5879e-02],\n",
      "          [ 6.3781e-02,  5.4150e-02,  1.1453e-01],\n",
      "          [-8.2668e-02,  1.4931e-01, -4.1710e-02]],\n",
      "\n",
      "         [[ 6.3778e-02,  1.6746e-01,  1.4881e-02],\n",
      "          [-5.8431e-02, -5.8588e-02,  6.7364e-02],\n",
      "          [-5.0658e-02,  1.1686e-01,  1.0945e-01]],\n",
      "\n",
      "         [[ 1.5695e-01,  2.6770e-02,  1.2614e-01],\n",
      "          [ 1.5768e-01, -1.0099e-01,  1.3442e-01],\n",
      "          [-2.1908e-02,  1.4474e-01,  7.5724e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.4907e-02, -3.8348e-02,  7.6578e-03],\n",
      "          [-1.8081e-01,  6.3772e-02,  9.0431e-03],\n",
      "          [ 1.5340e-01, -1.5907e-01, -6.3552e-02]],\n",
      "\n",
      "         [[ 4.0802e-02,  1.4424e-01, -4.4133e-02],\n",
      "          [-1.5352e-01, -1.0336e-01, -9.1199e-02],\n",
      "          [ 5.9668e-02,  6.9998e-03, -5.1710e-02]],\n",
      "\n",
      "         [[-1.6678e-01, -1.1912e-01,  1.3719e-01],\n",
      "          [-1.2069e-01, -3.1002e-03, -3.1505e-02],\n",
      "          [-6.6870e-02, -1.3790e-02, -1.2719e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0754e-02,  1.6512e-01, -3.7539e-02],\n",
      "          [-1.4390e-01, -1.0967e-01, -1.3238e-01],\n",
      "          [-6.1938e-02,  8.6232e-02,  4.3470e-02]],\n",
      "\n",
      "         [[ 3.2877e-02, -4.1549e-02, -1.7740e-01],\n",
      "          [ 3.1387e-02,  1.4577e-01, -2.8878e-02],\n",
      "          [ 4.0930e-02,  1.6311e-01,  1.2413e-01]],\n",
      "\n",
      "         [[-9.8024e-02, -1.5707e-01, -1.3870e-01],\n",
      "          [-4.9773e-02, -7.6807e-02, -1.3742e-01],\n",
      "          [-8.5975e-02,  6.0955e-02,  4.8848e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.1565e-02, -1.2867e-01,  1.6268e-01],\n",
      "          [-1.4952e-01,  1.3498e-01,  1.7528e-01],\n",
      "          [ 4.6782e-02,  3.9587e-02, -1.1507e-01]],\n",
      "\n",
      "         [[ 4.1771e-02, -1.8746e-01,  1.1895e-01],\n",
      "          [-6.2198e-02,  8.9534e-02,  1.4275e-01],\n",
      "          [ 1.3185e-01,  4.9883e-02,  3.3978e-02]],\n",
      "\n",
      "         [[ 6.9371e-02, -9.1049e-02, -1.0849e-01],\n",
      "          [-1.6276e-01, -7.7758e-03, -9.9889e-02],\n",
      "          [-4.9312e-02, -1.8998e-01, -4.4053e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.3513e-02,  1.4311e-01, -2.4283e-02],\n",
      "          [-1.2492e-01, -1.3009e-01, -1.6094e-01],\n",
      "          [ 7.1212e-02, -1.7603e-01, -9.4533e-02]],\n",
      "\n",
      "         [[-1.5057e-01,  1.9077e-01, -1.3490e-01],\n",
      "          [-5.6309e-03,  1.2061e-01,  4.7963e-02],\n",
      "          [-7.5035e-02,  1.7915e-01, -1.4130e-01]],\n",
      "\n",
      "         [[ 1.6259e-01,  9.8556e-02, -1.1114e-01],\n",
      "          [-1.9116e-01, -1.2117e-01,  3.7310e-02],\n",
      "          [ 9.0017e-02, -9.3466e-02,  1.6418e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7390e-01, -1.1006e-01,  1.8477e-01],\n",
      "          [ 1.2779e-01,  1.8690e-01, -1.1552e-01],\n",
      "          [ 1.4282e-01, -7.6765e-02,  2.1944e-02]],\n",
      "\n",
      "         [[ 2.7046e-02, -7.6562e-02, -1.2657e-01],\n",
      "          [-1.6972e-01, -3.5551e-02,  1.1676e-01],\n",
      "          [ 8.1211e-03, -1.1123e-01,  1.6300e-01]],\n",
      "\n",
      "         [[ 4.1463e-02,  1.2281e-01,  6.9518e-02],\n",
      "          [-8.4173e-03,  1.3511e-01,  1.4173e-01],\n",
      "          [ 4.9318e-02, -1.9021e-01, -8.4648e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.1066e-02,  1.8549e-01,  8.1601e-02],\n",
      "          [-1.7456e-01, -3.8793e-02, -1.8843e-01],\n",
      "          [ 3.1765e-02,  1.7441e-02,  9.5924e-02]],\n",
      "\n",
      "         [[-1.5225e-02, -1.8062e-01, -6.1815e-03],\n",
      "          [-4.9669e-02,  4.1746e-02,  8.8767e-03],\n",
      "          [-3.5121e-02,  1.7701e-02, -1.6860e-01]],\n",
      "\n",
      "         [[ 1.6299e-01, -1.1118e-01,  3.3549e-02],\n",
      "          [-4.7085e-02,  3.6962e-02,  1.7299e-01],\n",
      "          [ 1.3931e-01,  6.5147e-02, -1.3560e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.2554e-02,  6.3868e-02,  1.8728e-01],\n",
      "          [ 9.5218e-02,  1.6885e-04, -1.2494e-01],\n",
      "          [ 8.1795e-02, -1.4284e-01, -1.7728e-02]],\n",
      "\n",
      "         [[-1.1964e-01,  3.1000e-02, -1.4430e-01],\n",
      "          [-1.4478e-01, -1.7736e-01,  1.3240e-01],\n",
      "          [ 1.0458e-01, -6.6564e-02,  9.3936e-02]],\n",
      "\n",
      "         [[-1.8221e-01, -7.8169e-02,  1.1978e-01],\n",
      "          [-7.6192e-02, -2.7921e-02,  5.4900e-02],\n",
      "          [-8.3198e-02,  1.1686e-01, -5.2966e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5543e-01, -9.5655e-02, -1.2152e-01],\n",
      "          [ 3.5044e-02,  1.4004e-01,  1.7537e-01],\n",
      "          [ 1.8872e-01,  1.8759e-01, -1.7526e-02]],\n",
      "\n",
      "         [[ 5.1044e-02, -8.2265e-03, -1.8207e-02],\n",
      "          [ 1.4823e-01,  9.0736e-02, -3.6685e-02],\n",
      "          [-1.5820e-01, -1.7294e-01, -1.2390e-01]],\n",
      "\n",
      "         [[ 6.2544e-02,  2.7840e-02, -6.6019e-02],\n",
      "          [-1.9126e-01, -1.1002e-01,  3.1287e-02],\n",
      "          [-1.1078e-01, -9.3924e-02,  1.8888e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2843e-01,  1.4306e-01,  1.1494e-01],\n",
      "          [ 9.2048e-02, -1.3109e-01,  8.0672e-02],\n",
      "          [ 1.7715e-01, -5.8112e-04,  7.4237e-02]],\n",
      "\n",
      "         [[-9.4520e-02, -1.4034e-01,  1.2120e-01],\n",
      "          [-1.9019e-01, -1.5200e-01, -1.1584e-01],\n",
      "          [ 1.0842e-01,  2.1231e-02, -1.4126e-01]],\n",
      "\n",
      "         [[ 4.2729e-02,  1.8009e-01,  2.0032e-02],\n",
      "          [ 1.2803e-01, -1.4161e-01, -2.4816e-02],\n",
      "          [-8.9844e-02,  6.2252e-02,  1.6786e-02]]]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "torch.Size([16, 3, 3, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 3, 3, 3], expected input[100, 1, 32, 32] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-0a5e47a186e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-ad8a563a65fc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 349\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    350\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 3, 3, 3], expected input[100, 1, 32, 32] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.resize_(100, 1, 32, 32)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = error(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    # Decay learning rate\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.resize_(100, 1, 32, 32).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
