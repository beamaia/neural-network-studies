{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following [ResNet for MNIST with pytorch](https://www.kaggle.com/readilen/resnet-for-mnist-with-pytorch?scriptVersionId=6942243), using the MNIST dataset from torchvision.datasets instead of csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.datasets import MNIST\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "mnist_data = MNIST(root='../mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../mnist/\n",
       "    Split: Train"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing what dtype it returns\n",
    "type(mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting data into x_data (features) and y_data(labels)\n",
    "# normalizing x_data\n",
    "x_data = mnist_data.data/255.\n",
    "y_data = mnist_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting into train and test datasets. Size of train data is 85% and size of test data is 15%.\n",
    "# random_state=42\n",
    "features_train, features_test, targets_train, targets_test = train_test_split(x_data, y_data, test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting into train and test datasets. Size of train data is 80% and size of test data is 20%.\n",
    "# random_state=42\n",
    "features_train, features_test, targets_train, targets_test = train_test_split(x_data, y_data, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features train size: [48000, 28, 28]\n",
      "Features test size: [12000, 28, 28]\n",
      "Targets train size: [48000]\n",
      "Targets test size: [12000]\n"
     ]
    }
   ],
   "source": [
    "print(f'Features train size: {list(features_train.size())}')\n",
    "print(f'Features test size: {list(features_test.size())}')\n",
    "print(f'Targets train size: {list(targets_train.size())}')\n",
    "print(f'Targets test size: {list(targets_test.size())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing features dtype \n",
    "features_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAKr0lEQVR4nO3de2yddR3H8c+3p13ZBdiNO2MbHbiyqODChijglMlcIIbgALmIkIkRgiawJRoSJTCCiNxhEgRZhE1gIUCCoCvIWByCDHAosA2GC5eBY5SxS1nZen7+cQ7Jcfb5lj6nl2/b9ytZaM63v+c8PeG9X9cnz6mllAQgnprePgEA7SNOICjiBIIiTiAo4gSCIk4gKOLsR8xsgZnN6+3zQNcgzm5kZuvMbIOZDa14bLaZLe3F08rNzEaa2X1m9oGZbTSzhWa2R2+fV39FnN2vIOknvX0SnWVmhXYenidphKTxkhok7SPpsh48rQGFOLvfNZLmmNnwXQdmNs7MkpnVVjy21Mxmlz/+vpktN7PrzWyTmb1hZkeXH3+rvCufs8thR5tZk5ltMbOnzGxsxbEnlmfNZrbazE6tmC0ws9+Y2aNmtk3StHa+lvGSHkopbU4pfSTpQUmTqnp1kIk4u98KSUslzcm5fqqklySNkrRI0r2SjpQ0QdJZkm4xs2EVn3+mpCskjZb0D0kLJan8rXVT+Rh7Szpd0nwzO6xi7RmSrpS0u6S/tnMut0o60cxGmNkISadIeizn14UOEGfP+Lmki8xsrxxr/51Suiul1CbpPkljJF2eUmpNKS2R9IlKoX7qjymlZSmlVkmXSvqymY2RdKKkdeVj7UwpvSjpAUmzKtY+nFJanlIqppS2t3MuL0gaJOmD8p82SfNzfE34DIizB6SU/iXpEUk/zbH8PxUff1w+3q6PVe6cb1U871ZJzZL2lzRW0tTyt8ebzGyTSrvsvu2tzXC/pDUq7ax7SFor6Z5OfTX4zGo7/hR0kV+otPNcW/HYtvJ/h0jaXP64MpY8xnz6Qfnb3ZGS1qsU3lMppenO2o5uUTpc0oUppW3l49+m9r/9RRdg5+whKaXXVfq29McVj70v6R1JZ5lZwczOU+mnoNWYaWZfNbNBKv3b85mU0lsq7dyHmtnZZlZX/nOkmTV24tjPSZptZoPNbLCk81X69zC6AXH2rMslDd3lsR9ImqvSv+EmSXq6yudYpNIu3Sxpsko/NFJKaYukb6r0g6D1kt6TdLWk+k4c+zxJ4yS9rdJfKgdL2vWnxegixs3WQEzsnEBQxAkERZxAUMQJBOVe55xeM4ufFgHdrKm42Np7nJ0TCIo4gaCIEwiKOIGgiBMIijiBoIgTCIo4gaCIEwiKOIGgiBMIijiBoIgTCIo4gaCIEwiKOIGgiBMIijiBoIgTCIo4gaCIEwiKOIGgiBMIijiBoIgTCIo4gaCIEwiKOIGgiBMIijiBoIgTCIo4gaCIEwiKOIGgiBMIijiBoIgTCIo4gaBqe/sEBqLCqJGZs/VnTHTXbp7cWtVzP/+Nm935iMKQ3Md+c+dWd378wrnuvOGKlZmzYktLrnPqy9g5gaCIEwiKOIGgiBMIijiBoIgTCIo4gaC4zpnHlM+748HXbPCXj1iXOZs7qinPGXVCvTvdkdpyH3m/wmB3/vL3bnHnjQfNzpw1nP2S/+TF/OcdFTsnEBRxAkERJxAUcQJBEScQFHECQQ3ISylWN8idr5032Z0/cNr17ryxrq7T5/RZFVV05y3FHe588hMXufPUmv/v68Lu/nO/etyd/vxrd2TOTjj+h+7auiUr3HlfxM4JBEWcQFDECQRFnEBQxAkERZxAUMQJBNV/r3OaZY6aHxrrLn3lcP/WJqm665j3b907c3bFypnu2t3/NMydj/zd39z5IXrenVejcGiD/wlPVnHs1v53S1hH2DmBoIgTCIo4gaCIEwiKOIGgiBMIijiBoPrtdc43fnlU5qzj65i+1uTftzh1/sXufOxvX8uevf/PXOcUwdbGUVWtv645+9cfFpb7r0uq6pljYucEgiJOICjiBIIiTiAo4gSCIk4gKOIEguq31zmvPHlRtx37K7/2r2MeeMPT7jzynYlWm/2/xOr5R7hrHz/hug6O7v+KwItHrsqc3X2J/367B1ztv+Z9ETsnEBRxAkERJxAUcQJBEScQFHECQREnEFS/vc753NaDM2cnD22u6tjbR/XduwcLE8a781d/ln1P5poZt3VwdP86ZjV2Dum2Q4fFzgkERZxAUMQJBEWcQFDECQRFnEBQ/fZSyrIbst8aU1etqOrYL557ozufMeU0d15z4+jMWf2jz7lraw/Y352vuuQgd379Sb93598assWdV+OCt491508u+0Lm7NB73nPXRr4NLy92TiAo4gSCIk4gKOIEgiJOICjiBIIiTiAoSyn79qfpNbP67r1RZpmj1+8+3F36+DE3u/MDa6u7NerD4vbM2Rs7dnPXDqnxf/1gY11drnP6lPfrDS9ZP81d++Tj/uvaMG+lOy+2tLjz/qqpuLjd/1nZOYGgiBMIijiBoIgTCIo4gaCIEwiKOIGg+u91zioUGg9x5yPvfN+d3zX2ia48nR7V+IcLM2cNc57pwTMZOLjOCfQxxAkERZxAUMQJBEWcQFDECQRFnEBQ/fZ9a6vR9upr7nzjsf7Ldszp2dcKJenay+dnzqbU9+6l5eLo7Ps5a/fb1127813/vWXROeycQFDECQRFnEBQxAkERZxAUMQJBEWcQFBc58wh7dzpzgdv9H9b5BcHfZI5K6rgrl3R6s/3KnzszsfX+u+Lu3r67ZmzN6f5xz7z0jnufM97uB+0M9g5gaCIEwiKOIGgiBMIijiBoIgTCIq3xsyhZuhQd37OC6+481OGbcyc3bqpwV372KTh7rww6XPufJ8717vz28csdeeeJR/7r8tNEybmPnZ/xltjAn0McQJBEScQFHECQREnEBRxAkERJxAUt4zlYHX+y+Zdx+zIzU0z3PkE+bddtb282p2/e1y9O5+1ZGbmbPGER921R9c3u/OrTpnqzoc+8Kw7H2jYOYGgiBMIijiBoIgTCIo4gaCIEwiKOIGguM6Zw9o5h3XwGX/Jfey9u/lSX2ptdefvbNkz97GH1fjXUFv39PcC/27QgYedEwiKOIGgiBMIijiBoIgTCIo4gaCIEwiK65w5pCpftQvePjZzNvzhl9y1xeqeWltOP8qdXzZxQe5jf1jc7s6HbPB/NSL+FzsnEBRxAkERJxAUcQJBEScQFHECQXEppRe8sOGAzNnoljXu2tpxB7nzdd890J3/+Ue/cuf7FAa7c895a7/jznd75O+5jz0QsXMCQREnEBRxAkERJxAUcQJBEScQFHECQXGdsxc8/aWFmbPD7j7fXXvhEU+584tGPNjBs+e/jnnaWv/XE7bN/Cj3sfH/2DmBoIgTCIo4gaCIEwiKOIGgiBMIijiBoLjOmcO4h1v8TzjbH9c4fyeu+vodOc6o63x7zUnZw1N3uGuLLR28LugUdk4gKOIEgiJOICjiBIIiTiAo4gSCIk4gKK5z5lBY+Zo7n/r8Ge782cmLcj/38u117vzcZee68+Er6t35fveuypy1fdDsrkXXYucEgiJOICjiBIIiTiAo4gSCIk4gKOIEgrKUUuZwes2s7CGALtFUXGztPc7OCQRFnEBQxAkERZxAUMQJBEWcQFDECQRFnEBQxAkERZxAUMQJBEWcQFDECQRFnEBQxAkERZxAUMQJBEWcQFDECQRFnEBQxAkERZxAUO5bYwLoPeycQFDECQRFnEBQxAkERZxAUMQJBPVfWQ3tp2OrCAUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(features_train[12])\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Number \" + str(int(targets_train[12])))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, \n",
    "                     out_channels, \n",
    "                     kernel_size=3, \n",
    "                     stride=stride, \n",
    "                     padding=1, \n",
    "                     bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:blue\">Study notes:</span></b><br>\n",
    "[Conv2d](https://pytorch.org/docs/master/generated/torch.nn.Conv2d.html) parameters:\n",
    "\n",
    "- **in_channels (int)** – Number of channels in the input image\n",
    "- **out_channels (int)** – Number of channels produced by the convolution\n",
    "- **kernel_size (int or tuple)** – Size of the convolving kernel\n",
    "- **stride (int or tuple, optional)** – Stride of the convolution. Default: 1\n",
    "- **padding (int or tuple, optional)** – Zero-padding added to both sides of the input. Default: 0\n",
    "- **padding_mode (string, optional)** – 'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'\n",
    "- **dilation (int or tuple, optional)** – Spacing between kernel elements. Default: 1 \n",
    "- **groups (int, optional)** – Number of blocked connections from input channels to output channels. Default: 1\n",
    "- **bias (bool, optional)** – If True, adds a learnable bias to the output. Default: True\n",
    "\n",
    "In this function, a 2d convolution is applied, the kernel size is 3x3 with initially a stride of 1 (can be specified a different value). There is a padding of 0s (1 pixel border)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "            \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:blue\">Study notes:</span></b><br>\n",
    "\n",
    "On [this medium article (Residual blocks — Building blocks of ResNet)](https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec) there's a bit about what is a residual block.\n",
    "\n",
    "![Image](https://miro.medium.com/max/700/1*FqmD91PvbH7NKCnQWFJxvg.png)\n",
    "\n",
    "<center> Types of Residual Block. Source: <a href=\"https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec\"> Residual blocks - Building blocks of ResNet </a></center>\n",
    "\n",
    "In `__init__`:\n",
    "- 3x3 convolution;\n",
    "- [Batch normalization](https://arxiv.org/abs/1502.03167), size of out_channels and output is the same shape as input;\n",
    "- Rectified linear unit function (operation in-place);\n",
    "- 3x3 convolution, size of channels of input is the same as output channels size (produced by the convolution;\n",
    "- Batch normalization;\n",
    "- Downsample (uses nn.Sequential later on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(1, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[0], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[1], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        \n",
    "    \n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        \n",
    "        downsample = None\n",
    "        \n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        \n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 2500\n",
    "num_epochs = n_iters/ (len(features_train) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = int(num_epochs)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(features_train, targets_train)\n",
    "test = torch.utils.data.TensorDataset(features_test, targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7f344ff17160>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.SequentialSampler at 0x7f34505da880>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7f344ff17160>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_args = {\n",
    "    \"block\": ResidualBlock,\n",
    "    \"layers\": [2,2,2,2]\n",
    "}\n",
    "\n",
    "model = ResNet(**net_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 out of 5\n",
      "Iteration: 2250  Loss: 2.3137640953063965  Accuracy: 11.016666412353516 %\n",
      "Iteration: 2500  Loss: 2.3097715377807617  Accuracy: 11.016666412353516 %\n",
      "epoch 2 out of 5\n",
      "Iteration: 2750  Loss: 2.3192617893218994  Accuracy: 11.016666412353516 %\n",
      "Iteration: 3000  Loss: 2.3143579959869385  Accuracy: 10.824999809265137 %\n",
      "epoch 3 out of 5\n",
      "Iteration: 3250  Loss: 2.3006138801574707  Accuracy: 9.783333778381348 %\n",
      "Iteration: 3500  Loss: 2.300628185272217  Accuracy: 11.033333778381348 %\n",
      "epoch 4 out of 5\n",
      "Iteration: 3750  Loss: 2.3050332069396973  Accuracy: 9.641666412353516 %\n",
      "epoch 5 out of 5\n",
      "Iteration: 4000  Loss: 2.3042969703674316  Accuracy: 9.783333778381348 %\n",
      "Iteration: 4250  Loss: 2.3264737129211426  Accuracy: 9.800000190734863 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f'epoch {epoch + 1} out of {num_epochs}')\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        train  = Variable(images.resize_(batch_size, 1, 32, 32))\n",
    "        labels = Variable(labels)           \n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()   \n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)      \n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)   \n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()   \n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()  \n",
    "        \n",
    "        count += 1      \n",
    "        if count % 250 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for images, labels in test_loader:\n",
    "                images = Variable(images.resize_(batch_size, 1, 32, 32))                \n",
    "                outputs = model(images)                \n",
    "                predicted = torch.max(outputs.data, 1)[1]                \n",
    "                total += labels.size(0)              \n",
    "                correct += (predicted == labels).sum()         \n",
    "            \n",
    "            accuracy = 100 * correct / float(total)           \n",
    "\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            \n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1st attempt:**\n",
    "\n",
    "Did it wrong, iterations passed 2000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2nd-4th attempt:**\n",
    "\n",
    "`Loss:nan`\n",
    "\n",
    "**5th attempt:**\n",
    "\n",
    "Test: 15%, Train: 85%, for some weird reason the accuracy stayed the same.\n",
    "```\n",
    "0 4 (epoch/num_epochs)\n",
    "Iteration: 250  Loss: nan  Accuracy: 9.899999618530273 %\n",
    "Iteration: 500  Loss: nan  Accuracy: 9.899999618530273 %\n",
    "1 4\n",
    "Iteration: 750  Loss: nan  Accuracy: 9.899999618530273 %\n",
    "Iteration: 1000  Loss: nan  Accuracy: 9.899999618530273 %\n",
    "2 4\n",
    "Iteration: 1250  Loss: nan  Accuracy: 9.899999618530273 %\n",
    "Iteration: 1500  Loss: nan  Accuracy: 9.899999618530273 %\n",
    "3 4\n",
    "Iteration: 1750  Loss: nan  Accuracy: 9.899999618530273 %\n",
    "Iteration: 2000  Loss: nan  Accuracy: 9.899999618530273 %\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final attempt:**\n",
    "\n",
    "Test: 20%, Train: 80%.\n",
    "```\n",
    "epoch 0 out of 5\n",
    "Iteration: 250  Loss: 2.3006722927093506  Accuracy: 10.158333778381348 %\n",
    "Iteration: 500  Loss: 2.3206615447998047  Accuracy: 10.158333778381348 %\n",
    "epoch 1 out of 5\n",
    "Iteration: 750  Loss: 2.302372932434082  Accuracy: 10.216666221618652 %\n",
    "epoch 2 out of 5\n",
    "Iteration: 1000  Loss: 2.2932326793670654  Accuracy: 10.166666984558105 %\n",
    "Iteration: 1250  Loss: 2.292675495147705  Accuracy: 10.091666221618652 %\n",
    "epoch 3 out of 5\n",
    "Iteration: 1500  Loss: 2.302126407623291  Accuracy: 10.158333778381348 %\n",
    "Iteration: 1750  Loss: 2.3060832023620605  Accuracy: 10.158333778381348 %\n",
    "epoch 4 out of 5\n",
    "Iteration: 2000  Loss: 2.293761730194092  Accuracy: 10.149999618530273 %\n",
    "Iteration: 2250  Loss: 2.317558526992798  Accuracy: 10.158333778381348 %\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue\"><b>Study session observations:</b></span><br>\n",
    "<sub>A place for study sessions' observations/thoughts. At a new commit, the previous input will be commented, therefore hidden.</sub>\n",
    "\n",
    "***\n",
    "<!-- #### 15/07/2020:\n",
    "\n",
    "A bit confused about the model used, it's very much a black box where I can see the results and then somewhat understand, but I can't really replicate it. In the previous days, I tried first implementing it, just to see it in action, and now I'm trying to understand more about it.\n",
    "\n",
    "I think the first part of understanding is to search a bit more about the objects that I am using. I don't understand much about the objects themselves, what I can do with them and more. Today I tried to learn a bit more about the classes `torch.nn.modules.conv.Conv2d` and `torch.nn.modules.batchnorm.BatchNorm2d`. Might look into creating a different notebook in order to try to use the model and objects in different ways and also since this one is starting to get a bit polluted. -->\n",
    "\n",
    "<!-- #### 16/07/2020:\n",
    "\n",
    "Testing functions and methods moved to a different notebook. Tried increasing the number of epochs to 20 to see if the accuracy would change.  -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
